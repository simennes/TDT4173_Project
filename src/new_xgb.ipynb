{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../data/xgb/X_train.npz')['arr_0']\n",
    "y_train = np.load('../data/xgb/y_train.npz')['arr_0']\n",
    "x_val = np.load('../data/xgb/X_val.npz')['arr_0']\n",
    "y_val = np.load('../data/xgb/y_val.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515194, 174) (1515194, 12) (297840, 174) (297840, 12)\n",
      "[   7.50361    77.5834    308.1        17.1         1.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          7.57302    77.49505   307.6        17.3         1.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.         23.216667    7.65043    77.39404   306.8        16.9\n",
      "    1.          0.          0.          0.          0.          0.\n",
      "    0.          0.         26.383333    7.71275    77.31394   307.9\n",
      "   16.9         1.          0.          0.          0.          0.\n",
      "    0.          0.          0.         21.416666    7.77191    77.23585\n",
      "  307.         16.3         1.          0.          0.          0.\n",
      "    0.          0.          0.          0.         20.983334    7.81285\n",
      "   77.18147   307.6        16.1         1.          0.          0.\n",
      "    0.          0.          0.          0.          0.         15.016666\n",
      "    7.86929    77.11032   309.5        16.1         1.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "   20.183332    7.92585    77.03811   308.7        16.          1.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.         20.416666    7.98258    76.9688    310.4        16.\n",
      "    1.          0.          0.          0.          0.          0.\n",
      "    0.          0.         20.          8.03598    76.90095   307.5\n",
      "   16.1         1.          0.          0.          0.          0.\n",
      "    0.          0.          0.         19.2        22.       6500.\n",
      "  199.          0.          1.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    1.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          1.\n",
      "    0.          0.          0.          0.          0.          1.      ]\n"
     ]
    }
   ],
   "source": [
    "# print x_train[0] but not whith numbers on scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:56.72972\n",
      "[1]\tvalidation_0-rmse:51.97716\n",
      "[2]\tvalidation_0-rmse:47.53011\n",
      "[3]\tvalidation_0-rmse:43.73538\n",
      "[4]\tvalidation_0-rmse:40.24186\n",
      "[5]\tvalidation_0-rmse:37.16665\n",
      "[6]\tvalidation_0-rmse:34.47039\n",
      "[7]\tvalidation_0-rmse:32.22323\n",
      "[8]\tvalidation_0-rmse:30.15011\n",
      "[9]\tvalidation_0-rmse:28.37117\n",
      "[10]\tvalidation_0-rmse:26.92095\n",
      "[11]\tvalidation_0-rmse:25.58990\n",
      "[12]\tvalidation_0-rmse:24.46076\n",
      "[13]\tvalidation_0-rmse:23.49653\n",
      "[14]\tvalidation_0-rmse:22.68042\n",
      "[15]\tvalidation_0-rmse:21.99121\n",
      "[16]\tvalidation_0-rmse:21.40270\n",
      "[17]\tvalidation_0-rmse:20.92262\n",
      "[18]\tvalidation_0-rmse:20.51221\n",
      "[19]\tvalidation_0-rmse:20.16772\n",
      "[20]\tvalidation_0-rmse:19.91798\n",
      "[21]\tvalidation_0-rmse:19.66154\n",
      "[22]\tvalidation_0-rmse:19.45342\n",
      "[23]\tvalidation_0-rmse:19.27750\n",
      "[24]\tvalidation_0-rmse:19.12958\n",
      "[25]\tvalidation_0-rmse:19.02033\n",
      "[26]\tvalidation_0-rmse:18.92748\n",
      "[27]\tvalidation_0-rmse:18.83695\n",
      "[28]\tvalidation_0-rmse:18.76346\n",
      "[29]\tvalidation_0-rmse:18.69636\n",
      "[30]\tvalidation_0-rmse:18.64676\n",
      "[31]\tvalidation_0-rmse:18.60186\n",
      "[32]\tvalidation_0-rmse:18.55500\n",
      "[33]\tvalidation_0-rmse:18.51317\n",
      "[34]\tvalidation_0-rmse:18.47388\n",
      "[35]\tvalidation_0-rmse:18.44392\n",
      "[36]\tvalidation_0-rmse:18.42020\n",
      "[37]\tvalidation_0-rmse:18.39629\n",
      "[38]\tvalidation_0-rmse:18.36948\n",
      "[39]\tvalidation_0-rmse:18.34726\n",
      "[40]\tvalidation_0-rmse:18.32000\n",
      "[41]\tvalidation_0-rmse:18.30048\n",
      "[42]\tvalidation_0-rmse:18.28371\n",
      "[43]\tvalidation_0-rmse:18.26245\n",
      "[44]\tvalidation_0-rmse:18.24331\n",
      "[45]\tvalidation_0-rmse:18.22549\n",
      "[46]\tvalidation_0-rmse:18.21026\n",
      "[47]\tvalidation_0-rmse:18.19436\n",
      "[48]\tvalidation_0-rmse:18.18214\n",
      "[49]\tvalidation_0-rmse:18.16965\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=50, max_depth=9, learning_rate=0.1, tree_method='hist', subsample=0.95, colsample_bytree=0.7, objective='reg:squarederror')\n",
    "\n",
    "model.fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=True)\n",
    "\n",
    "model.save_model('../models/xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use optuna to find the best hyperparameters. using device cuda\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from optuna.integration.xgboost import XGBoostPruningCallback\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'tree_method': 'hist',\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'device': 'cuda'\n",
    "    }\n",
    "\n",
    "    pruning_callback = XGBoostPruningCallback(trial, 'validation_0-rmse')\n",
    "    model = XGBRegressor(**param)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False, callbacks=[pruning_callback])\n",
    "\n",
    "    y_pred = model.predict(x_val)\n",
    "    rmse = np.sqrt(np.mean((y_val - y_pred) ** 2))\n",
    "    return rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, prefix='', suffix='', decimals=1, length=100, fill='â–ˆ', printEnd=\"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end=printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_last_known_sequence(last_known_seq, example_length, vessel_data_length, test_time):\n",
    "    data = last_known_seq[0]\n",
    "\n",
    "    time_prev = last_known_seq[1][-1]\n",
    "    test_time = pd.Timestamp(test_time)\n",
    "    time_delta = np.array((test_time - time_prev).total_seconds() / 60)\n",
    "\n",
    "    history = data[example_length:example_length*11]\n",
    "    vessel_data = data[example_length*11:(example_length*11 + vessel_data_length)]\n",
    "    vessel_type = data[-4:]\n",
    "\n",
    "    time_data = np.zeros(5+24+7)\n",
    "\n",
    "    # get 5 dummy variables for month\n",
    "    month = test_time.month\n",
    "    for i in range(5):\n",
    "        time_data[i] = month == i + 1\n",
    "\n",
    "    # get 24 dummy variables for hour\n",
    "    hour = test_time.hour\n",
    "    for i in range(24):\n",
    "        time_data[5 + i] = hour == i\n",
    "\n",
    "    # get 7 dummy variables for weekday\n",
    "    weekday = test_time.weekday()\n",
    "    for i in range(7):\n",
    "        time_data[29 + i] = weekday == i\n",
    "\n",
    "    last_known_sequence = np.hstack([history, time_delta, vessel_data, time_data, vessel_type])\n",
    "\n",
    "    return last_known_sequence\n",
    "\n",
    "def adjust_prediction(pred):\n",
    "    pred[0] = max(-90, min(90, pred[0]))\n",
    "    pred[1] = max(-180, min(180, pred[1]))\n",
    "    pred[2] = max(0, min(359, pred[2]))\n",
    "    pred[3] = max(0, min(1022, pred[3]))\n",
    "    \n",
    "    # set pred[4:] to 1 for the highest and 0 for the rest\n",
    "    max_index = np.argmax(pred[4:])\n",
    "    pred[4:] = 0\n",
    "    pred[4 + max_index] = 1\n",
    "\n",
    "    return pred\n",
    "\n",
    "def format_recurrently(last_known_seq, pred, example_length, vessel_data_length, time_prev, test_time):\n",
    "\n",
    "    data = last_known_seq[example_length:]\n",
    "    history = data[:(example_length*9)]\n",
    "\n",
    "    pred_input = np.hstack([adjust_prediction(pred), np.array(data[example_length*9])])\n",
    "    \n",
    "    time_prev = pd.Timestamp(time_prev)\n",
    "    test_time = pd.Timestamp(test_time)\n",
    "    time_delta = np.array((test_time - time_prev).total_seconds() / 60)\n",
    "\n",
    "    vessel_data = data[(example_length*9 + 1):(example_length*9 + 1 + vessel_data_length)]\n",
    "    vessel_type = data[-4:]\n",
    "\n",
    "    time_data = np.zeros(5+24+7)\n",
    "\n",
    "    # get 5 dummy variables for month\n",
    "    month = test_time.month\n",
    "    for i in range(5):\n",
    "        time_data[i] = month == i + 1\n",
    "\n",
    "    # get 24 dummy variables for hour\n",
    "    hour = test_time.hour\n",
    "    for i in range(24):\n",
    "        time_data[5 + i] = hour == i\n",
    "\n",
    "    # get 7 dummy variables for weekday\n",
    "    weekday = test_time.weekday()\n",
    "    for i in range(7):\n",
    "        time_data[29 + i] = weekday == i\n",
    "\n",
    "    last_known_sequence = np.hstack([history, pred_input, time_delta, vessel_data, time_data, vessel_type])\n",
    "\n",
    "\n",
    "    return last_known_sequence\n",
    "\n",
    "\n",
    "\n",
    "def format_history_visual(last_known_seq, vesselId):\n",
    "    times = pd.to_datetime(last_known_seq[1])\n",
    "    last_known_seq = last_known_seq[0]\n",
    "\n",
    "    latitudes = last_known_seq[:11*13:13]\n",
    "    longitudes = last_known_seq[1:1+11*13:13]\n",
    "\n",
    "    history = pd.DataFrame({'time': times, 'vesselId': [vesselId for i in range(len(latitudes))], 'latitude': latitudes, 'longitude': longitudes})\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "def predict_future_positions(model, test_data, x_final, example_length, vessel_data_length, seq_length=10, return_first=False):\n",
    "\n",
    "    IDs = []\n",
    "    latitudes = [] \n",
    "    longitudes = []\n",
    "    vessel_ids = []\n",
    "\n",
    "    times_visual, latitudes_visual, longitudes_visual, vessel_ids_visual = [], [], [], []\n",
    "\n",
    "    vesselId = ''\n",
    "\n",
    "    # iterate over the test_data\n",
    "    j = 0\n",
    "    for i in range(len(test_data)):\n",
    "\n",
    "        if test_data.iloc[i]['vesselId'] != vesselId:\n",
    "            vesselId = test_data.iloc[i]['vesselId']\n",
    "            last_known_sequence = format_last_known_sequence(x_final[j], example_length, vessel_data_length, test_data.iloc[i]['time'])\n",
    "\n",
    "            if j != 0:\n",
    "                result = pd.DataFrame({'ID': IDs, 'latitude': latitudes, 'longitude': longitudes})\n",
    "                result = result.sort_values(by='ID').reset_index(drop=True)\n",
    "                visualizer = pd.concat([visualizer, pd.DataFrame({'time': times_visual, 'vesselId': vessel_ids_visual, 'latitude': latitudes_visual, 'longitude': longitudes_visual})])\n",
    "                visualizer.to_csv(f'../data/visual/visualizer_{j}.csv', index=False)\n",
    "\n",
    "                times_visual, latitudes_visual, longitudes_visual, vessel_ids_visual = [], [], [], []\n",
    "                visualizer = format_history_visual(x_final[j], vesselId)\n",
    "            else:\n",
    "                visualizer = format_history_visual(x_final[j], vesselId)\n",
    "                \n",
    "            j += 1\n",
    "\n",
    "        else:\n",
    "            last_known_sequence = format_recurrently(last_known_sequence, pred[0], example_length, vessel_data_length, time_prev, test_data.iloc[i]['time'])\n",
    "\n",
    "\n",
    "        # Predict future positions\n",
    "        pred = model.predict(last_known_sequence.reshape(1, -1))\n",
    "\n",
    "        vessel_ids.append('pred_'+vesselId)\n",
    "        time_prev = test_data.iloc[i]['time']\n",
    "\n",
    "        IDs.append(test_data.iloc[i]['ID'])\n",
    "        latitudes.append(pred[0][0])\n",
    "        longitudes.append(pred[0][1])\n",
    "\n",
    "        times_visual.append(test_data.iloc[i]['time'])\n",
    "        latitudes_visual.append(pred[0][0])\n",
    "        longitudes_visual.append(pred[0][1])\n",
    "        vessel_ids_visual.append('pred_' + vesselId)\n",
    "\n",
    "        if j > 10:\n",
    "            break\n",
    "        \n",
    "\n",
    "        #progress_bar(i, len(test_data))\n",
    "\n",
    "        \n",
    "\n",
    "    # return a dataframe sorted by ID\n",
    "    result = pd.DataFrame({'ID': IDs, 'latitude': latitudes, 'longitude': longitudes})\n",
    "    result = result.sort_values(by='ID').reset_index(drop=True)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "x_final_train = pickle.load(open('../data/xgb/with_val/x_final_train.pkl', 'rb'))\n",
    "x_val_stripped = pd.read_csv('../data/xgb/with_val/stripped_val_data.csv')\n",
    "\n",
    "# load model\n",
    "model = XGBRegressor()\n",
    "model.load_model('../models/xgb_model.json')\n",
    "\n",
    "example_length = 13\n",
    "vessel_data_length = 3\n",
    "\n",
    "result = predict_future_positions(model, x_val_stripped, x_final_train, example_length, vessel_data_length, return_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store result to csv\n",
    "result.to_csv('../data/xgb/xgb_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID   latitude  longitude\n",
      "0  321  41.139430   2.326052\n",
      "1  322  41.156430   2.469431\n",
      "2  323  41.156430   2.532059\n",
      "3  324  41.154522   2.646584\n",
      "4  325  41.154522   2.828715\n",
      "   latitude  longitude   ID\n",
      "0  41.21099    2.20128  321\n",
      "1  41.25944    2.19747  322\n",
      "2  41.26718    2.20361  323\n",
      "3  41.26558    2.21807  324\n",
      "4  41.26185    2.23374  325\n",
      "Mean geodesic distance in kilometers: 3163.442090075849\n"
     ]
    }
   ],
   "source": [
    "# load the result and the stripped val data. calculate the mean geodesic distance in kilomiters\n",
    "result = pd.read_csv('../data/xgb/xgb_result.csv')\n",
    "val_data = pd.read_csv('../data/xgb/y_val_stripped.csv')\n",
    "\n",
    "result = result.sort_values(by='ID').reset_index(drop=True)\n",
    "val_data = val_data.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "print(result.head())\n",
    "print(val_data.head())\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "mean_distance = 0\n",
    "for i in range(len(result)):\n",
    "    pred = (result.iloc[i]['latitude'], result.iloc[i]['longitude'])\n",
    "    true = (val_data.iloc[i]['latitude'], val_data.iloc[i]['longitude'])\n",
    "    mean_distance += geodesic(pred, true).kilometers\n",
    "\n",
    "mean_distance /= len(result)\n",
    "print('Mean geodesic distance in kilometers:', mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_positions_test(model, test_data, x_final, example_length, vessel_data_length, vesselID_dict ,seq_length=10, return_first=False):\n",
    "\n",
    "    # sort the test_data by vesselId and time\n",
    "    test_data = test_data.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "\n",
    "    IDs = []\n",
    "    latitudes = [] \n",
    "    longitudes = []\n",
    "    times = []\n",
    "    vessel_ids = []\n",
    "\n",
    "    vesselId = ''\n",
    "    formated_output = []\n",
    "\n",
    "    # iterate over the test_data\n",
    "    j = 0\n",
    "    for i in range(len(test_data)):\n",
    "\n",
    "        if test_data.iloc[i]['vesselId'] != vesselId:\n",
    "            vesselId = test_data.iloc[i]['vesselId']\n",
    "            index = int(vesselID_dict[vesselId])\n",
    "            last_known_sequence = format_last_known_sequence(x_final[index], example_length, vessel_data_length, test_data.iloc[i]['time'])\n",
    "            #if j == 0:\n",
    "                #visualizer = format_history_visual(x_final[index])\n",
    "            j += 1\n",
    "            if return_first and j == 2:\n",
    "                result = pd.DataFrame({'ID': IDs, 'latitude': latitudes, 'longitude': longitudes})\n",
    "                result = result.sort_values(by='ID').reset_index(drop=True)\n",
    "                #visualizer = pd.concat([visualizer, pd.DataFrame({'time': times, 'vesselId': vessel_ids, 'latitude': latitudes, 'longitude': longitudes})])\n",
    "                #visualizer.to_csv('../data/visualizer.csv', index=False)\n",
    "                return result\n",
    "\n",
    "        else:\n",
    "            last_known_sequence = format_recurrently(last_known_sequence, pred[0], example_length, vessel_data_length, time_prev, test_data.iloc[i]['time'])\n",
    "\n",
    "        if j < 10:\n",
    "            print(last_known_sequence)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        # Predict future positions\n",
    "        pred = model.predict(last_known_sequence.reshape(1, -1))\n",
    "\n",
    "        #print(pred)\n",
    "\n",
    "        times.append(test_data.iloc[i]['time'])\n",
    "        vessel_ids.append('pred_'+vesselId)\n",
    "        time_prev = test_data.iloc[i]['time']\n",
    "\n",
    "        IDs.append(test_data.iloc[i]['ID'])\n",
    "        latitudes.append(pred[0][0])\n",
    "        longitudes.append(pred[0][1])\n",
    "        \n",
    "\n",
    "        #progress_bar(i, len(test_data))\n",
    "\n",
    "        \n",
    "\n",
    "    # return a dataframe sorted by ID\n",
    "    result = pd.DataFrame({'ID': IDs, 'latitude': latitudes, 'longitude': longitudes})\n",
    "    result = result.sort_values(by='ID').reset_index(drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "687\n"
     ]
    }
   ],
   "source": [
    "print(x_test['vesselId'].nunique())\n",
    "print(len(x_final_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final_train = pickle.load(open('../data/xgb/x_final_train.pkl', 'rb'))\n",
    "x_test = pd.read_csv('../data/ais_test.csv')\n",
    "vesselId_dict = pickle.load(open('../data/xgb/vesselId_dict.pkl', 'rb'))\n",
    "\n",
    "# load model\n",
    "model = XGBRegressor()\n",
    "model.load_model('../models/xgb_model.json')\n",
    "\n",
    "example_length = 13\n",
    "vessel_data_length = 3\n",
    "\n",
    "result = predict_future_positions_test(model, x_test, x_final_train, example_length, vessel_data_length, vesselId_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store result to csv. rename the columns to match the submission format ('ID', 'latitude_predicted', 'longitude_predicted')\n",
    "result.columns = ['ID', 'latitude_predicted', 'longitude_predicted']\n",
    "result.to_csv('../predictions/submission_xgb_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_visualizer(filepath, train):\n",
    "\n",
    "\n",
    "    i = 1\n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            path = f'{filepath}visualizer_{i}.csv'\n",
    "\n",
    "            # Load the visualizer\n",
    "            visualizer = pd.read_csv(path)\n",
    "\n",
    "            # find the vesselId of the first row\n",
    "            vesselId = visualizer['vesselId'].iloc[0]\n",
    "\n",
    "            # find the corresponding rows in the train data\n",
    "            train_vessel = train[train['vesselId'] == vesselId]\n",
    "\n",
    "            # find the corresponding times for the 'pred_' vesselId\n",
    "            times = visualizer[visualizer['vesselId'] == 'pred_' + vesselId]['time']\n",
    "\n",
    "            # find the values in train with the corresponding times\n",
    "            train_vessel = train_vessel[train_vessel['time'].isin(times)]\n",
    "\n",
    "            # add prefix 'true_' to the vesselId in train\n",
    "            train_vessel['vesselId'] = 'true_' + train_vessel['vesselId']\n",
    "            train_vessel = train_vessel[['time', 'vesselId', 'latitude', 'longitude']]\n",
    "\n",
    "            # add rows to the visualizer where the vesselId is 'true_vesselId'\n",
    "            visualizer = pd.concat([visualizer, train_vessel])\n",
    "\n",
    "            # save full_visualizer to csv\n",
    "            visualizer.to_csv(path)\n",
    "\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/ais_train.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_visualizer('../data/visual/', train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
